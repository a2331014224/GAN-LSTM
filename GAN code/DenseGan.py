# -*- coding: utf-8 -*-
"""
@author: yixin
"""
from keras.layers import Dense,Dropout,Input
from keras.models import Model,Sequential
from keras.layers.advanced_activations import LeakyReLU
from keras.optimizers import Adam
import numpy as np
import HXYutil

"""Select GPU"""
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"

losses = []
acc=[]

x_train = HXYutil.getdata()
x_size=len(x_train)

# Building generator and discriminator
def build_generator():
    model=Sequential()
    model.add(Dense(units=512,input_dim=20))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(units=1024))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(units=20))
    model.add(LeakyReLU(alpha=0.2))
    g_adam = Adam(0.0005,0.5)
    model.compile(loss='binary_crossentropy',optimizer=g_adam)
    return model
generator=build_generator()
generator.build((None,20))

def build_discriminator():
  model=Sequential()
  model.add(Dense(units=512,input_dim=20))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(units=256))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(units=128))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(units=1,activation='sigmoid'))

  d_adam = Adam(0.0005,0.5)
  model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=d_adam)
  model.build((None,20))
  return model

discriminator=build_discriminator()



def build_GAN(discriminator,generator):
  discriminator.trainable=False
  GAN_input=Input(shape=(20,))
  x=generator(GAN_input)
  GAN_output=discriminator(x)
  GAN=Model(inputs=GAN_input,outputs=GAN_output)
  GAN_rmsprop = Adam(0.0005,0.5)

  GAN.compile(loss='binary_crossentropy',optimizer=GAN_rmsprop)
  return GAN

GAN=build_GAN(discriminator,generator)

def train_GAN(time):
    generator = build_generator()
    discriminator = build_discriminator()
    GAN = build_GAN(discriminator, generator)

    train = 0
    for train in range (time):
        start = 0
        for start in range(x_size):
            print("time %d Epoch %d" % (train+1 ,start))
            #The length of a protein
            cur_legth=len(x_train[start])

#            noise1 = np.random.randint(-9, 9, size=(cur_legth,20), dtype='int16')
            noise1 = np.random.normal(0,1,(cur_legth,20))
            #One protein corresponds to the pseudo protein
            fake_images1 = generator.predict(noise1)
            
            real_images = x_train[start]

           #Establish true and fake data labels
            label_fake = np.zeros(cur_legth)
            label_real = np.ones(cur_legth)
            for j in range(cur_legth):
                label_real[j] = np.array([0.9])

            x = np.concatenate([fake_images1, real_images])
            y = np.concatenate([label_fake, label_real])

            #  Training discriminator
            discriminator.trainable = True
            d_loss,d_acc = discriminator.train_on_batch(x, y)

            #  Training generator
            discriminator.trainable = False
            g_loss = GAN.train_on_batch(fake_images1, label_real)
           
            losses.append((d_loss, g_loss))
            acc.append(d_acc)

           
            if start > len(x_train):
                start = 0
                print('epoch 1')
            if start % 20 == 0:
               
                print('discriminator loss at step %s: %s' % (start, d_loss))
                print('generator loss at step %s: %s' % (start, g_loss))
                print('discriminator acc at step %s: %s' % (start, d_acc))




#Start training
train_GAN(20)
#Setting generator weights is not trainable
generator.trainable=False
generator.save('DenseGAN_net_nosort.h5')
#Get generator output
i=0
x2=[]
for i in range(x_size):
    z1=generator.predict(x_train[i])
    #X2 is the fake data generated by the generator
    x2.append(z1)

#The generated features are spliced with PSSM
conall=[]
j=0
for j in range(x_size):
    con_one=np.concatenate((x_train[j],x2[j]),axis=1)
    conall.append(con_one)

x_con=np.array(conall)
np.save('X_train_sort.npy', x_con)